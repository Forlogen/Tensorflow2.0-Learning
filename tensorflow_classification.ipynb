{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-beta0'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import,print_function,unicode_literals,division\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'WebOfScience/WOS11967/X.txt'\n",
    "label_path = 'WebOfScience/WOS11967/YL1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(text):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD',text) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def process_text(text):\n",
    "    \n",
    "    text = unicode_to_ascii(text.lower().strip())\n",
    "    # create a space between a word and the punctuation following it\n",
    "    text = re.sub(r\"([?.!,¿])\", r\" \\1 \", text)\n",
    "    text = re.sub(r'[\" \"]+', \" \", text)\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    text = '<start> ' + text +  ' <end>'\n",
    "    \n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    text = []\n",
    "    \n",
    "    with open(path,encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            text_ = str(line.strip().split('\\t'))\n",
    "            text.append(process_text(text_))\n",
    "    return text   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of data is:11967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<start> the aim of this study was to investigate a the behavioral cues that are displayed by , and trait judgments formed about , anxious interviewees , and b why anxious interviewees receive lower interview performance ratings . the behavioral expression of interview anxiety model was created as a conceptual framework to explore these relations . we videotaped and transcribed mock job interviews , obtained ratings of interview anxiety and interview performance , and trained raters to assess several verbal and nonverbal cues and trait judgments . the results indicated that few behavioral cues , but several traits were related to interviewee and interviewer ratings of interview anxiety . two factors emerged from our factor analysis on the trait judgments assertiveness and interpersonal warmth . mediation analyses were performed and indicated that assertiveness and interpersonal warmth mediated the relation between interview anxiety and interview performance . speech rate words spoken per minute and assertiveness were found to mediate the relation between interviewee and interviewer ratings of interview anxiety . overall , the results indicated that interviewees should focus less on their nervous tics and more on the broader impressions that they convey . our findings indicate that anxious interviewees may want to focus on how assertive and interpersonally warm they appear to interviewers . to our knowledge , this is the first study to use a validated interview anxiety measure to examine behavioral cues and traits exhibited by anxious interviewees . we offer new insight into why anxious interviewees receive lower interview performance ratings . <end>'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data(data_path)\n",
    "\n",
    "print ('The size of data is:{}'.format(len(data)))\n",
    "\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of label is:11967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = list()\n",
    "\n",
    "with open(label_path,'r') as f:\n",
    "    for line in f:\n",
    "        label_ = line.strip().split('\\n')\n",
    "        label.append(label_)\n",
    "    \n",
    "print ('The size of label is:{}'.format(len(label)))\n",
    "\n",
    "label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    \n",
    "    text_tokenizer.fit_on_texts(text)\n",
    "    \n",
    "    tensor = text_tokenizer.texts_to_sequences(text)\n",
    "    \n",
    "    return tensor,text_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tensor, data_tokenizer = tokenize(data)\n",
    "label_tensor, label_tokenizer = tokenize(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_data_length = 300\n",
    "\n",
    "data_tensor = keras.preprocessing.sequence.pad_sequences(data_tensor,maxlen = max_data_length,padding = 'post')\n",
    "label_tensor = keras.preprocessing.sequence.pad_sequences(label_tensor,maxlen = 1,padding = 'post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11967\n"
     ]
    }
   ],
   "source": [
    "data_tensor\n",
    "\n",
    "print (len(data_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [6],\n",
       "       [4],\n",
       "       ...,\n",
       "       [1],\n",
       "       [4],\n",
       "       [6]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 ---> <start>\n",
      "1 ---> the\n",
      "367 ---> aim\n",
      "4 ---> of\n",
      "14 ---> this\n",
      "26 ---> study\n",
      "21 ---> was\n",
      "7 ---> to\n",
      "373 ---> investigate\n",
      "8 ---> a\n",
      "1 ---> the\n",
      "685 ---> behavioral\n",
      "1201 ---> cues\n",
      "12 ---> that\n",
      "17 ---> are\n",
      "2382 ---> displayed\n",
      "16 ---> by\n",
      "3 ---> ,\n",
      "5 ---> and\n",
      "1258 ---> trait\n",
      "1686 ---> judgments\n",
      "1989 ---> formed\n",
      "134 ---> about\n",
      "3 ---> ,\n",
      "4470 ---> anxious\n",
      "12159 ---> interviewees\n",
      "3 ---> ,\n",
      "5 ---> and\n",
      "103 ---> b\n",
      "2398 ---> why\n",
      "4470 ---> anxious\n",
      "12159 ---> interviewees\n",
      "2978 ---> receive\n",
      "226 ---> lower\n",
      "3326 ---> interview\n",
      "83 ---> performance\n",
      "1714 ---> ratings\n",
      "2 ---> .\n",
      "1 ---> the\n",
      "685 ---> behavioral\n",
      "214 ---> expression\n",
      "4 ---> of\n",
      "3326 ---> interview\n",
      "425 ---> anxiety\n",
      "43 ---> model\n",
      "21 ---> was\n",
      "1568 ---> created\n",
      "15 ---> as\n",
      "8 ---> a\n",
      "2172 ---> conceptual\n",
      "302 ---> framework\n",
      "7 ---> to\n",
      "986 ---> explore\n",
      "33 ---> these\n",
      "1664 ---> relations\n",
      "2 ---> .\n",
      "22 ---> we\n",
      "9011 ---> videotaped\n",
      "5 ---> and\n",
      "7339 ---> transcribed\n",
      "10053 ---> mock\n",
      "4092 ---> job\n",
      "2042 ---> interviews\n",
      "3 ---> ,\n",
      "203 ---> obtained\n",
      "1714 ---> ratings\n",
      "4 ---> of\n",
      "3326 ---> interview\n",
      "425 ---> anxiety\n",
      "5 ---> and\n",
      "3326 ---> interview\n",
      "83 ---> performance\n",
      "3 ---> ,\n",
      "5 ---> and\n",
      "2795 ---> trained\n",
      "5131 ---> raters\n",
      "7 ---> to\n",
      "477 ---> assess\n",
      "191 ---> several\n",
      "894 ---> verbal\n",
      "5 ---> and\n",
      "548 ---> nonverbal\n",
      "1201 ---> cues\n",
      "5 ---> and\n",
      "1258 ---> trait\n",
      "1686 ---> judgments\n",
      "2 ---> .\n",
      "1 ---> the\n",
      "27 ---> results\n",
      "578 ---> indicated\n",
      "12 ---> that\n",
      "755 ---> few\n",
      "685 ---> behavioral\n",
      "1201 ---> cues\n",
      "3 ---> ,\n",
      "69 ---> but\n",
      "191 ---> several\n",
      "733 ---> traits\n",
      "20 ---> were\n",
      "114 ---> related\n",
      "7 ---> to\n",
      "26652 ---> interviewee\n",
      "5 ---> and\n",
      "19677 ---> interviewer\n",
      "1714 ---> ratings\n",
      "4 ---> of\n",
      "3326 ---> interview\n",
      "425 ---> anxiety\n",
      "2 ---> .\n",
      "57 ---> two\n",
      "172 ---> factors\n",
      "1930 ---> emerged\n",
      "24 ---> from\n",
      "67 ---> our\n",
      "275 ---> factor\n",
      "54 ---> analysis\n",
      "13 ---> on\n",
      "1 ---> the\n",
      "1258 ---> trait\n",
      "1686 ---> judgments\n",
      "15967 ---> assertiveness\n",
      "5 ---> and\n",
      "1447 ---> interpersonal\n",
      "2796 ---> warmth\n",
      "2 ---> .\n",
      "4860 ---> mediation\n",
      "342 ---> analyses\n",
      "20 ---> were\n",
      "208 ---> performed\n",
      "5 ---> and\n",
      "578 ---> indicated\n",
      "12 ---> that\n",
      "15967 ---> assertiveness\n",
      "5 ---> and\n",
      "1447 ---> interpersonal\n",
      "2796 ---> warmth\n",
      "790 ---> mediated\n",
      "1 ---> the\n",
      "1092 ---> relation\n",
      "38 ---> between\n",
      "3326 ---> interview\n",
      "425 ---> anxiety\n",
      "5 ---> and\n",
      "3326 ---> interview\n",
      "83 ---> performance\n",
      "2 ---> .\n",
      "2248 ---> speech\n",
      "212 ---> rate\n",
      "2568 ---> words\n",
      "9012 ---> spoken\n",
      "591 ---> per\n",
      "5446 ---> minute\n",
      "5 ---> and\n",
      "15967 ---> assertiveness\n",
      "20 ---> were\n",
      "106 ---> found\n",
      "7 ---> to\n",
      "4589 ---> mediate\n",
      "1 ---> the\n",
      "1092 ---> relation\n",
      "38 ---> between\n",
      "26652 ---> interviewee\n",
      "5 ---> and\n",
      "19677 ---> interviewer\n",
      "1714 ---> ratings\n",
      "4 ---> of\n",
      "3326 ---> interview\n",
      "425 ---> anxiety\n",
      "2 ---> .\n",
      "368 ---> overall\n",
      "3 ---> ,\n",
      "1 ---> the\n",
      "27 ---> results\n",
      "578 ---> indicated\n",
      "12 ---> that\n",
      "12159 ---> interviewees\n",
      "310 ---> should\n",
      "569 ---> focus\n",
      "242 ---> less\n",
      "13 ---> on\n",
      "47 ---> their\n",
      "3948 ---> nervous\n",
      "26653 ---> tics\n",
      "5 ---> and\n",
      "51 ---> more\n",
      "13 ---> on\n",
      "1 ---> the\n",
      "4047 ---> broader\n",
      "2588 ---> impressions\n",
      "12 ---> that\n",
      "131 ---> they\n",
      "5367 ---> convey\n",
      "2 ---> .\n",
      "67 ---> our\n",
      "171 ---> findings\n",
      "504 ---> indicate\n",
      "12 ---> that\n",
      "4470 ---> anxious\n",
      "12159 ---> interviewees\n",
      "75 ---> may\n",
      "6684 ---> want\n",
      "7 ---> to\n",
      "569 ---> focus\n",
      "13 ---> on\n",
      "159 ---> how\n",
      "17627 ---> assertive\n",
      "5 ---> and\n",
      "15968 ---> interpersonally\n",
      "5215 ---> warm\n",
      "131 ---> they\n",
      "1884 ---> appear\n",
      "7 ---> to\n",
      "15969 ---> interviewers\n",
      "2 ---> .\n",
      "7 ---> to\n",
      "67 ---> our\n",
      "256 ---> knowledge\n",
      "3 ---> ,\n",
      "14 ---> this\n",
      "10 ---> is\n",
      "1 ---> the\n",
      "118 ---> first\n",
      "26 ---> study\n",
      "7 ---> to\n",
      "60 ---> use\n",
      "8 ---> a\n",
      "939 ---> validated\n",
      "3326 ---> interview\n",
      "425 ---> anxiety\n",
      "608 ---> measure\n",
      "7 ---> to\n",
      "751 ---> examine\n",
      "685 ---> behavioral\n",
      "1201 ---> cues\n",
      "5 ---> and\n",
      "733 ---> traits\n",
      "1361 ---> exhibited\n",
      "16 ---> by\n",
      "4470 ---> anxious\n",
      "12159 ---> interviewees\n",
      "2 ---> .\n",
      "22 ---> we\n",
      "1701 ---> offer\n",
      "78 ---> new\n",
      "1811 ---> insight\n",
      "89 ---> into\n",
      "2398 ---> why\n",
      "4470 ---> anxious\n",
      "12159 ---> interviewees\n",
      "2978 ---> receive\n",
      "226 ---> lower\n",
      "3326 ---> interview\n",
      "83 ---> performance\n",
      "1714 ---> ratings\n",
      "2 ---> .\n",
      "19 ---> <end>\n"
     ]
    }
   ],
   "source": [
    "def convert(text,tensor):\n",
    "    for t in tensor:\n",
    "        if t != 0:\n",
    "            print (\"%d ---> %s\" % (t,text.index_word[t]))\n",
    "            \n",
    "convert(data_tokenizer,data_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tokenizer.index_word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, label_train, label_test = train_test_split(data_tensor, label_tensor,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=20350, shape=(9573, 6), dtype=float32, numpy=\n",
       "array([[0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_label_train = []\n",
    "\n",
    "for line in label_train:\n",
    "    for value in line:\n",
    "        _label_train.append(value)\n",
    "        \n",
    "_label_train = np.array(_label_train,dtype = np.int64)\n",
    "\n",
    "label_train_one_hot= tf.one_hot(_label_train,6)\n",
    "label_train_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=20356, shape=(9573, 6), dtype=float32, numpy=\n",
       "array([[0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot= tf.one_hot(_label_train,6)\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((16, 300), (16, 1)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "buffer_size = 32\n",
    "\n",
    "steps_per_epoch = len(data_train) // batch_size\n",
    "\n",
    "vocab_data_size = len(data_tokenizer.word_index) + 1\n",
    "vocab_label_size = len(label_tokenizer.word_index) + 1\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data_train,label_train)).shuffle(buffer_size)\n",
    "dataset = dataset.batch(batch_size,drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 300, 32)           1679712   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_11  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 1,680,342\n",
      "Trainable params: 1,680,342\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 32\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_data_size,embedding_dim,input_length = max_data_length),\n",
    "    keras.layers.GlobalAveragePooling1D(),\n",
    "    keras.layers.Dense(16,activation = 'relu'),\n",
    "    keras.layers.Dense(6,activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7658 samples, validate on 1915 samples\n",
      "Epoch 1/30\n",
      "7658/7658 [==============================] - 1s 160us/sample - loss: 0.6795 - accuracy: 0.7732 - val_loss: 0.6643 - val_accuracy: 0.8185\n",
      "Epoch 2/30\n",
      "7658/7658 [==============================] - 1s 131us/sample - loss: 0.6469 - accuracy: 0.8597 - val_loss: 0.6250 - val_accuracy: 0.8696\n",
      "Epoch 3/30\n",
      "7658/7658 [==============================] - 1s 134us/sample - loss: 0.6009 - accuracy: 0.8706 - val_loss: 0.5720 - val_accuracy: 0.8696\n",
      "Epoch 4/30\n",
      "7658/7658 [==============================] - 1s 131us/sample - loss: 0.5419 - accuracy: 0.8706 - val_loss: 0.5081 - val_accuracy: 0.8696\n",
      "Epoch 5/30\n",
      "7658/7658 [==============================] - 1s 128us/sample - loss: 0.4771 - accuracy: 0.8706 - val_loss: 0.4464 - val_accuracy: 0.8696\n",
      "Epoch 6/30\n",
      "7658/7658 [==============================] - 1s 131us/sample - loss: 0.4225 - accuracy: 0.8706 - val_loss: 0.4035 - val_accuracy: 0.8696\n",
      "Epoch 7/30\n",
      "7658/7658 [==============================] - 1s 131us/sample - loss: 0.3904 - accuracy: 0.8706 - val_loss: 0.3831 - val_accuracy: 0.8696\n",
      "Epoch 8/30\n",
      "7658/7658 [==============================] - 1s 130us/sample - loss: 0.3762 - accuracy: 0.8706 - val_loss: 0.3743 - val_accuracy: 0.8696\n",
      "Epoch 9/30\n",
      "7658/7658 [==============================] - 1s 132us/sample - loss: 0.3690 - accuracy: 0.8706 - val_loss: 0.3688 - val_accuracy: 0.8696\n",
      "Epoch 10/30\n",
      "7658/7658 [==============================] - 1s 129us/sample - loss: 0.3641 - accuracy: 0.8706 - val_loss: 0.3647 - val_accuracy: 0.8696\n",
      "Epoch 11/30\n",
      "7658/7658 [==============================] - 1s 132us/sample - loss: 0.3605 - accuracy: 0.8706 - val_loss: 0.3616 - val_accuracy: 0.8696\n",
      "Epoch 12/30\n",
      "7658/7658 [==============================] - 1s 131us/sample - loss: 0.3577 - accuracy: 0.8706 - val_loss: 0.3592 - val_accuracy: 0.8696\n",
      "Epoch 13/30\n",
      "7658/7658 [==============================] - 1s 130us/sample - loss: 0.3554 - accuracy: 0.8706 - val_loss: 0.3571 - val_accuracy: 0.8696\n",
      "Epoch 14/30\n",
      "7658/7658 [==============================] - 1s 130us/sample - loss: 0.3533 - accuracy: 0.8706 - val_loss: 0.3551 - val_accuracy: 0.8696\n",
      "Epoch 15/30\n",
      "7658/7658 [==============================] - 1s 135us/sample - loss: 0.3513 - accuracy: 0.8706 - val_loss: 0.3533 - val_accuracy: 0.8696\n",
      "Epoch 16/30\n",
      "7658/7658 [==============================] - 1s 134us/sample - loss: 0.3493 - accuracy: 0.8706 - val_loss: 0.3515 - val_accuracy: 0.8696\n",
      "Epoch 17/30\n",
      "7658/7658 [==============================] - 1s 130us/sample - loss: 0.3473 - accuracy: 0.8706 - val_loss: 0.3496 - val_accuracy: 0.8696\n",
      "Epoch 18/30\n",
      "7658/7658 [==============================] - 1s 131us/sample - loss: 0.3453 - accuracy: 0.8706 - val_loss: 0.3477 - val_accuracy: 0.8696\n",
      "Epoch 19/30\n",
      "7658/7658 [==============================] - 1s 130us/sample - loss: 0.3432 - accuracy: 0.8706 - val_loss: 0.3457 - val_accuracy: 0.8696\n",
      "Epoch 20/30\n",
      "7658/7658 [==============================] - 1s 132us/sample - loss: 0.3409 - accuracy: 0.8706 - val_loss: 0.3436 - val_accuracy: 0.8696\n",
      "Epoch 21/30\n",
      "7658/7658 [==============================] - 1s 130us/sample - loss: 0.3385 - accuracy: 0.8706 - val_loss: 0.3413 - val_accuracy: 0.8696\n",
      "Epoch 22/30\n",
      "7658/7658 [==============================] - 1s 130us/sample - loss: 0.3359 - accuracy: 0.8706 - val_loss: 0.3387 - val_accuracy: 0.8696\n",
      "Epoch 23/30\n",
      "7658/7658 [==============================] - 1s 131us/sample - loss: 0.3330 - accuracy: 0.8706 - val_loss: 0.3361 - val_accuracy: 0.8696\n",
      "Epoch 24/30\n",
      "7658/7658 [==============================] - 1s 130us/sample - loss: 0.3299 - accuracy: 0.8706 - val_loss: 0.3330 - val_accuracy: 0.8696\n",
      "Epoch 25/30\n",
      "7658/7658 [==============================] - 1s 126us/sample - loss: 0.3261 - accuracy: 0.8706 - val_loss: 0.3292 - val_accuracy: 0.8696\n",
      "Epoch 26/30\n",
      "7658/7658 [==============================] - 1s 128us/sample - loss: 0.3216 - accuracy: 0.8706 - val_loss: 0.3249 - val_accuracy: 0.8697\n",
      "Epoch 27/30\n",
      "7658/7658 [==============================] - 1s 130us/sample - loss: 0.3168 - accuracy: 0.8709 - val_loss: 0.3202 - val_accuracy: 0.8701\n",
      "Epoch 28/30\n",
      "7658/7658 [==============================] - 1s 128us/sample - loss: 0.3114 - accuracy: 0.8714 - val_loss: 0.3152 - val_accuracy: 0.8706\n",
      "Epoch 29/30\n",
      "7658/7658 [==============================] - 1s 130us/sample - loss: 0.3057 - accuracy: 0.8724 - val_loss: 0.3098 - val_accuracy: 0.8715\n",
      "Epoch 30/30\n",
      "7658/7658 [==============================] - 1s 131us/sample - loss: 0.2997 - accuracy: 0.8735 - val_loss: 0.3041 - val_accuracy: 0.8724\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = keras.optimizers.Adam(),\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(data_train,label_train_one_hot,epochs = 30,batch_size = 512,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2394/2394 [==============================] - 0s 188us/sample - loss: 0.3062 - accuracy: 0.8710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3062440793068088, 0.8709968]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_label_test = []\n",
    "\n",
    "for line in label_test:\n",
    "    for value in line:\n",
    "        _label_test.append(value)\n",
    "        \n",
    "_label_test = np.array(_label_test,dtype = np.int64)\n",
    "\n",
    "label_test_one_hot= tf.one_hot(_label_test,6)\n",
    "\n",
    "result = model.evaluate(data_test,label_test_one_hot)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.plot(epochs, acc, 'bo', label = 'Traing acc')\n",
    "plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
    "plt.title('Trainging and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.ylim((0.5,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52491, 32)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 词嵌入矩阵\n",
    "e = model.layers[0]\n",
    "weights = e.get_weights()[0]\n",
    "weights.shape # (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "# 获取vecs.tsv 和 meta.tsv\n",
    "out_v = io.open('vecs.tsv','w',encoding = 'utf-8')\n",
    "out_m = io.open('meta.tsv','w',encoding = 'utf-8')\n",
    "\n",
    "for word_num in range(1,vocab_data_size):\n",
    "    word = data_tokenizer.index_word[word_num]\n",
    "    embeddings = weights[word_num]\n",
    "    out_m.write(word + \"\\n\")\n",
    "    out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
    "\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
